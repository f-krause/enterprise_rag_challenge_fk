{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Haystack",
   "id": "236e94323759847c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:15:53.675562Z",
     "start_time": "2025-02-04T20:15:53.019787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "653254e2b67ff75a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:15:53.690590Z",
     "start_time": "2025-02-04T20:15:53.677005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"../data\" \n",
    "files = [\"yellow_pages.pdf\"]"
   ],
   "id": "2fd69f548981be90",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:15:53.721069Z",
     "start_time": "2025-02-04T20:15:53.692139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_json(os.path.join(data_path, \"dev_questions.json\"))\n",
    "df.head()"
   ],
   "id": "a155b4d816013515",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           reference  \\\n",
       "0  The report of YELLOW PAGES LIMITED (Petra Diam...   \n",
       "1  The report is from YELLOW PAGES LIMITED (Petra...   \n",
       "2  The total revenues of YELLOW PAGES LIMITED (Pe...   \n",
       "3  The total revenues of YELLOW PAGES LIMITED (Pe...   \n",
       "4  The basic income per share in Q2 of 2021 of YE...   \n",
       "\n",
       "                                               query  response  \n",
       "0  What was the accounts receivable of 'Petra Dia...       NaN  \n",
       "1  What was the total assets of 'TransUnion' in t...       NaN  \n",
       "2  What was the total revenue for Petra Diamonds ...       NaN  \n",
       "3  By how much did the total revenue for Petra Di...       NaN  \n",
       "4  What was the total revenue for Petra Diamonds ...       NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The report of YELLOW PAGES LIMITED (Petra Diam...</td>\n",
       "      <td>What was the accounts receivable of 'Petra Dia...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The report is from YELLOW PAGES LIMITED (Petra...</td>\n",
       "      <td>What was the total assets of 'TransUnion' in t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The total revenues of YELLOW PAGES LIMITED (Pe...</td>\n",
       "      <td>What was the total revenue for Petra Diamonds ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The total revenues of YELLOW PAGES LIMITED (Pe...</td>\n",
       "      <td>By how much did the total revenue for Petra Di...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The basic income per share in Q2 of 2021 of YE...</td>\n",
       "      <td>What was the total revenue for Petra Diamonds ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:15:55.486860Z",
     "start_time": "2025-02-04T20:15:53.722072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# From https://haystack.deepset.ai/integrations/arize-phoenix\n",
    "from openinference.instrumentation.haystack import HaystackInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import (\n",
    "    OTLPSpanExporter,\n",
    ")\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "endpoint = \"http://localhost:6006/v1/traces\" # The URL to your Phoenix instance\n",
    "tracer_provider = trace_sdk.TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
    "\n",
    "HaystackInstrumentor().instrument(tracer_provider=tracer_provider)"
   ],
   "id": "241ae51e1a1527c1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:16:56.699729Z",
     "start_time": "2025-02-04T20:16:42.259913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load PDFs\n",
    "from haystack.components.converters.pypdf import PyPDFToDocument\n",
    "from datetime import datetime\n",
    "\n",
    "converter = PyPDFToDocument()\n",
    "results = converter.run(sources=[os.path.join(data_path, \"eval\", file) for file in files], meta={\"date_added\": datetime.now().isoformat()})\n",
    "documents = results[\"documents\"]\n",
    "type(documents[0])"
   ],
   "id": "2ed7b7811415924c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:22:04.406322Z",
     "start_time": "2025-02-04T20:22:02.596359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split document\n",
    "from haystack import Document\n",
    "from haystack_experimental.components.splitters import HierarchicalDocumentSplitter\n",
    "\n",
    "doc = Document(content=\"This is a simple test document\")\n",
    "splitter = HierarchicalDocumentSplitter(block_sizes={3, 2}, split_overlap=0, split_by=\"word\")\n",
    "documents_split = splitter.run(documents)"
   ],
   "id": "a24af65d40aca8b0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:22:25.515458Z",
     "start_time": "2025-02-04T20:22:25.497378Z"
    }
   },
   "cell_type": "code",
   "source": "type(documents_split)",
   "id": "6c77a0b7bffc4780",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:25:08.528869Z",
     "start_time": "2025-02-04T20:25:08.141466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Document Store\n",
    "from haystack_integrations.document_stores.chroma import ChromaDocumentStore\n",
    "from haystack import Document\n",
    "\n",
    "document_store = ChromaDocumentStore()\n",
    "document_store.write_documents(documents)\n",
    "# document_store.write_documents([\n",
    "#     Document(content=\"This is the first document.\"),\n",
    "#     Document(content=\"This is the second document.\")\n",
    "# ])\n",
    "print(document_store.count_documents())"
   ],
   "id": "cdca7768e40ac9a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document 6ef58163625e88e0168d9c607793055ac16c619f28347caa1a8bef9878fbaad1 contains `meta` values of unsupported types for the keys: __parent_id, __children_ids. These items will be discarded. Supported types are: str, int, float, bool.\n",
      "Add of existing embedding ID: 6ef58163625e88e0168d9c607793055ac16c619f28347caa1a8bef9878fbaad1\n",
      "Insert of existing embedding ID: 6ef58163625e88e0168d9c607793055ac16c619f28347caa1a8bef9878fbaad1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ad5a944ead1123d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:26:15.733579Z",
     "start_time": "2025-02-04T20:26:08.172448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from haystack import Document, Pipeline\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack_integrations.components.retrievers.chroma import ChromaQueryTextRetriever\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Given these documents, answer the question.\n",
    "Documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "retriever = ChromaQueryTextRetriever(document_store)\n",
    "# retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "llm = OpenAIGenerator()\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "question = \"Who lives in Paris?\"\n",
    "results = rag_pipeline.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "    }\n",
    ")"
   ],
   "id": "c7311fa28145657a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:26:36.239850Z",
     "start_time": "2025-02-04T20:26:36.234940Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "9bc63c10b9826442",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': ['The provided documents do not contain any information about individuals living in Paris or any specific context related to Paris. Therefore, I cannot provide an answer to the question regarding who lives in Paris based on the given content.'],\n",
       "  'meta': [{'model': 'gpt-4o-mini-2024-07-18',\n",
       "    'index': 0,\n",
       "    'finish_reason': 'stop',\n",
       "    'usage': {'completion_tokens': 43,\n",
       "     'prompt_tokens': 59488,\n",
       "     'total_tokens': 59531,\n",
       "     'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0),\n",
       "     'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}}]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate results",
   "id": "f67fac9e175353e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import nest_asyncio\n",
    "\n",
    "from phoenix.evals import HallucinationEvaluator, OpenAIModel, QAEvaluator, run_evals\n",
    "\n",
    "nest_asyncio.apply()  # This is needed for concurrency in notebook environments\n",
    "\n",
    "# Set your OpenAI API key\n",
    "eval_model = OpenAIModel(model=\"gpt-4o-mini-2024-07-18\")\n",
    "\n",
    "# Define your evaluators\n",
    "hallucination_evaluator = HallucinationEvaluator(eval_model)\n",
    "qa_evaluator = QAEvaluator(eval_model)\n",
    "\n",
    "# We have to make some minor changes to our dataframe to use the column names expected by our evaluators\n",
    "# for `hallucination_evaluator` the input df needs to have columns 'output', 'input', 'context'\n",
    "# for `qa_evaluator` the input df needs to have columns 'output', 'input', 'reference'\n",
    "df[\"context\"] = df[\"reference\"]\n",
    "df.rename(columns={\"query\": \"input\", \"response\": \"output\"}, inplace=True)\n",
    "assert all(column in df.columns for column in [\"output\", \"input\", \"context\", \"reference\"])\n",
    "\n",
    "# Run the evaluators, each evaluator will return a dataframe with evaluation results\n",
    "# We upload the evaluation results to Phoenix in the next step\n",
    "hallucination_eval_df, qa_eval_df = run_evals(\n",
    "    dataframe=df, evaluators=[hallucination_evaluator, qa_evaluator], provide_explanation=True\n",
    ")"
   ],
   "id": "2978a1ac08a4d0b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
